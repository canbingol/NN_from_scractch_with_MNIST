# MNIST Two-Layer Neural Network from Scratch
This project is a fully from-scratch implementation of a two-layer neural network designed to recognize handwritten digits in the MNIST dataset, without using any pre-built neural network libraries. The Python code covers all the essential steps, from data loading and preprocessing to the forward propagation and backpropagation stages in the training loop.

About the Project
The primary goal of this project is to recognize handwritten digits in the MNIST dataset through a custom-built neural network. This project uses only basic Python functionalities to construct the neural network, keeping library dependencies minimal.

Features
* Data Preprocessing: The MNIST dataset is loaded and normalized for training.
* Feedforward: Data flows from the input layer to the output layer, applying activation functions at each stage.
* Backpropagation: The error function is calculated and used to update weights through backpropagation.
* Training and Testing: The model is trained over a defined number of epochs on the training set, and its accuracy is evaluated on the test set.
